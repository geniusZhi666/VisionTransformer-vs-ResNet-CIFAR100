{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import resnet18\n",
    "from models.resnet import resnet34\n",
    "from models.resnet import resnet50\n",
    "from models.resnet import resnet101\n",
    "from models.resnet import resnet152\n",
    "\n",
    "#计算模型参数量\n",
    "def para_sum(model):\n",
    "    para = sum([np.prod(list(p.size())) for p in model.parameters()])\n",
    "    print('Model {} : params: {:4f}M'.format(model._get_name(), para / 1e6))\n",
    "    return para\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ResNet : params: 11.220132M\n",
      "Model ResNet : params: 21.328292M\n",
      "Model ResNet : params: 23.705252M\n",
      "Model ResNet : params: 42.697380M\n",
      "Model ResNet : params: 58.341028M\n"
     ]
    }
   ],
   "source": [
    "#分别输出各个模型的参数量\n",
    "if __name__ == '__main__':\n",
    "    model = resnet18()\n",
    "    para_sum(model)\n",
    "    model = resnet34()\n",
    "    para_sum(model)\n",
    "    model = resnet50()\n",
    "    para_sum(model)\n",
    "    model = resnet101()\n",
    "    para_sum(model)\n",
    "    model = resnet152()\n",
    "    para_sum(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model VisionTransformer : params: 31.801700M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31801700"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.visiontransformer import VisionTransformer\n",
    "patch_size = 4\n",
    "max_len = 100\n",
    "embed_dim = 512\n",
    "classes = 100\n",
    "layers = 24\n",
    "channels = 3\n",
    "heads = 16\n",
    "net = VisionTransformer(patch_size, max_len, embed_dim, classes, layers, channels, heads)\n",
    "para_sum(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
